# Lesson 08

## Goals

1. Implement much of FastAI library from the Foundations:
    - Basic Matrix Calculus, Training Loops with Callbacks, Custom Optimizer, Custom Annealing, Regularization, Dataset Loader, and Blocks
    - Lots of Layers and Architectures
    - Jupyter Dev, Testing, and Docs
2. Read papers and implement them (and we'll do some new research!)
3. Learn:
    - Object Detection
    - Seq2Seq/Attention
    - Transformer & Transformer XL
    - CycleGAN
    - Audio
4. Performance Tuning:
    - Distributed Training
    - JIT
    - CUDA/C++
5. Implement <i>some</i> of FastAI library in Swift

## Required Background

    1. Affine Functions & Non-Linearities
    2. Parameters & Activations
    3. Random Init & Transfer Learning
    4. Stochastic Gradient Descent, Momentum, and ADAM Optimizer
    5. Convolutions
    6. Batch-norm
    7. Dropout
    8. Data Augmentation
    9. Weight Decay
    10. Res/Dense Blocks
    11. Image Classification and Regression
    12. Embeddings
    13. Continuous and Categorical Variables
    14. Collaborative Filtering
    15. Language Models, NLP Classification
    16. Segmentation, U-NET, GANs

## General Training Framework

1. Overfit your model
2. Reduce over-fitting

## How to Avoid Overfitting (Prioritized Order)

1. More Data
2. Data Augmentation
3. Generalizable Architectures
4. Regularization
5. Reduce Architecture Complexity

## Math Resources

1. Wikipedia:

    https://en.wikipedia.org/wiki/List_of_mathematical_symbols

2. Detexify:

    http://detexify.kirelabs.org/classify.html

3. Matrix Multiplication:

    http://matrixmultiplication.xyz/

## Steps to a Modern CNN Model

1. Matrix Multiplication
2. ReLU / Initialization
3. Fully-Connected Forward Pass
4. Fully-Connected Backward Pass
5. Training Loop
6. Convolution
7. Optimizer
8. Batch-Norm
9. ResNet

